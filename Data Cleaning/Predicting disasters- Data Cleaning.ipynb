{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook goes through a necasssary step of cleaning the data before it is used for exploratory data analysis. \n",
    "* The input of this notebook is a training dataset in csv format sourced from Kaggle. \n",
    "* The output of this notebook is a Term frequency-inverse document frequency(TF-IDF) Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Understanding the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re           # regular expression \n",
    "import string       # String Handling\n",
    "import random       #For selecting random rows\n",
    "import nltk         # Natural langauage processing toolkit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the training data into a dataframe using pandas and viewing the top 20 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Three people died from the heat wave so far</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Haha South Tampa is getting flooded hah- WAIT ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#raining #flooding #Florida #TampaBay #Tampa 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Flood in Bago Myanmar #We arrived Bago</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Damage to school bus on 80 in multi car crash ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What's up man?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I love fruits</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Summer is lovely</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My car is so fast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What a goooooooaaaaaal!!!!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword location                                               text  \\\n",
       "0    1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1    4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2    5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3    6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4    7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5    8     NaN      NaN  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6   10     NaN      NaN  #flood #disaster Heavy rain causes flash flood...   \n",
       "7   13     NaN      NaN  I'm on top of the hill and I can see a fire in...   \n",
       "8   14     NaN      NaN  There's an emergency evacuation happening now ...   \n",
       "9   15     NaN      NaN  I'm afraid that the tornado is coming to our a...   \n",
       "10  16     NaN      NaN        Three people died from the heat wave so far   \n",
       "11  17     NaN      NaN  Haha South Tampa is getting flooded hah- WAIT ...   \n",
       "12  18     NaN      NaN  #raining #flooding #Florida #TampaBay #Tampa 1...   \n",
       "13  19     NaN      NaN            #Flood in Bago Myanmar #We arrived Bago   \n",
       "14  20     NaN      NaN  Damage to school bus on 80 in multi car crash ...   \n",
       "15  23     NaN      NaN                                     What's up man?   \n",
       "16  24     NaN      NaN                                      I love fruits   \n",
       "17  25     NaN      NaN                                   Summer is lovely   \n",
       "18  26     NaN      NaN                                  My car is so fast   \n",
       "19  28     NaN      NaN                       What a goooooooaaaaaal!!!!!!   \n",
       "\n",
       "    target  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "5        1  \n",
       "6        1  \n",
       "7        1  \n",
       "8        1  \n",
       "9        1  \n",
       "10       1  \n",
       "11       1  \n",
       "12       1  \n",
       "13       1  \n",
       "14       1  \n",
       "15       0  \n",
       "16       0  \n",
       "17       0  \n",
       "18       0  \n",
       "19       0  "
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "train_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 20 rows in 'Keyword' and 'Location' column are NaNs. Now Checking if there are nulls in other columns of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      "id          7613 non-null int64\n",
      "keyword     7552 non-null object\n",
      "location    5080 non-null object\n",
      "text        7613 non-null object\n",
      "target      7613 non-null int64\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking number of unique values in 'keywords' and 'location'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.keyword.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3342"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.location.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A glimpse at 50 rows from the 'locations' column selected randomly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Milton keynes',\n",
       " '#UNITE THE BLUE  ',\n",
       " 'germany',\n",
       " 'Madisonville TN',\n",
       " 'South, England',\n",
       " 'Burbank,CA',\n",
       " 'Reston, VA, USA',\n",
       " 'Frankfort, KY',\n",
       " 'Orbost, Victoria, Australia',\n",
       " 'port matilda pa',\n",
       " 'on a catwalk somewhere',\n",
       " 'Holland MI via Houston, CLE',\n",
       " 'East Lansing, MI',\n",
       " 'Based out of Portland, Oregon',\n",
       " 'Ogba, Lagos, Nigeria',\n",
       " 'Garrett',\n",
       " 'ÌÏT: -26.695807,27.837865',\n",
       " 'The Universe',\n",
       " 'Terlingua, Texas',\n",
       " 'The ?? below ???',\n",
       " 'The Netherlands',\n",
       " 'America | New Zealand ',\n",
       " 'North Dartmouth, Massachusetts',\n",
       " 'Oklahoma City',\n",
       " 'Arvada, CO',\n",
       " 'MIchigan',\n",
       " 'Glendale, CA',\n",
       " 'Winnipeg, Manitoba',\n",
       " 'Ideally under a big tree',\n",
       " 'The Orwellion police-state',\n",
       " 'Cape Cod, Massachusetts USA',\n",
       " 'Temporary Towers',\n",
       " 'All around the world!',\n",
       " 'Alvin, TX',\n",
       " 'Washington State',\n",
       " 'Bellville, Ohio',\n",
       " 'International Action',\n",
       " 'Enniscrone & Aughris, Sligo ',\n",
       " 'Indianapolis, IN',\n",
       " 'Thane',\n",
       " 'ÌÏT: 10.614817868480726,12.195582811791382',\n",
       " 'Stay Tuned ;) ',\n",
       " 'Kingswinford',\n",
       " 'Mooseknuckle, Maine',\n",
       " 'Trost District',\n",
       " 'Arkansas',\n",
       " 'Higher Places',\n",
       " 'home ',\n",
       " 'Head Office: United Kingdom',\n",
       " 'The P (South Philly)']"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(list((train_df.location.unique())),k=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A glimpse at 50 rows from the 'keywords' column selected randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sinking',\n",
       " 'sirens',\n",
       " 'destroyed',\n",
       " 'survivors',\n",
       " 'battle',\n",
       " 'curfew',\n",
       " 'twister',\n",
       " 'meltdown',\n",
       " 'blazing',\n",
       " 'hostage',\n",
       " 'refugees',\n",
       " 'blizzard',\n",
       " 'structural%20failure',\n",
       " 'mass%20murder',\n",
       " 'hailstorm',\n",
       " 'blaze',\n",
       " 'burning',\n",
       " 'wounded',\n",
       " 'evacuation',\n",
       " 'weapons',\n",
       " 'collided',\n",
       " 'drown',\n",
       " nan,\n",
       " 'earthquake',\n",
       " 'flames',\n",
       " 'crush',\n",
       " 'eyewitness',\n",
       " 'desolation',\n",
       " 'wreck',\n",
       " 'screamed',\n",
       " 'hijack',\n",
       " 'buildings%20on%20fire',\n",
       " 'flooding',\n",
       " 'radiation%20emergency',\n",
       " 'fatality',\n",
       " 'drowned',\n",
       " 'thunder',\n",
       " 'destroy',\n",
       " 'floods',\n",
       " 'devastation',\n",
       " 'aftershock',\n",
       " 'army',\n",
       " 'avalanche',\n",
       " 'hostages',\n",
       " 'danger',\n",
       " 'drought',\n",
       " 'disaster',\n",
       " 'collide',\n",
       " 'mudslide',\n",
       " 'displaced']"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(list((train_df.keyword.unique())),k=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A glimpse at 30 rows from the 'text' column selected randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@Jude_Mugabi not that all abortions get you traumatised. At times you are okay with the decision due to reasons like rape',\n",
       " \"Ever since my Facebook #Mets meltdown after the Padres fiasco- mets are 6-0. You're welcome\",\n",
       " 'OH MY GOD RYANS IN TROUBLE http://t.co/ADIp0UnXHU',\n",
       " 'Windstorm lastingness perquisite - acquiesce in a twister retreat: ZiUW http://t.co/iRt4kkgsJx',\n",
       " '@wocowae Police Officer Wounded Suspect Dead After Exchanging Shots http://t.co/oiOeCbsh1f ushed',\n",
       " '#Flood in Bago Myanmar #We arrived Bago',\n",
       " 'saving babies from burning buildings soaking cake in a shit tonne of alcohol mat is a man after my own heart ?? #GBBO',\n",
       " 'http://t.co/FhI4qBpwFH @FredOlsenCruise Please take the #FaroeIslands off your itinerary until the mass murder of dolphins &amp; whales stops.',\n",
       " 'U.S. record hurricane drought. http://t.co/fE9hIVfMxq',\n",
       " 'I liked a @YouTube video http://t.co/V57NUgmGKT US CANADA RADIATION UPDATE EMERGENCY FISHING CLOSURES',\n",
       " 'My take away: preservation parks r an imposition &amp; a danger to African people. I never imagined!  https://t.co/Gi2P9TUVBI',\n",
       " 'Police kill hatchet-wielding gunman who opened fire inside Nashville movie theater: AåÊmiddle-aged manåÊarmed wi... http://t.co/tyD47NfL5x',\n",
       " '~Still echoes of their screams~',\n",
       " \"I added a video to a @YouTube playlist http://t.co/bcjYleRRYX Ori and the Bind forest ep 6 'Fire and death'\",\n",
       " 'Police expand search for missing pregnant woman in Beloeil: Police in Richelieu-Saint-Laurent are expanding th... http://t.co/hMuyzmv8qH',\n",
       " 'Man my stomach feel like a tsunami ??.',\n",
       " 'You messed up my feeling like a hurricane damaged this broken home',\n",
       " 'CONFIRMED: Sanchez Hazard and Bolasie will be out for the rest of the season. https://t.co/7Ct01nEptL',\n",
       " \"It's like God wants me to become a mass murderer with how many dickheads I have to deal with on a daily basis.\",\n",
       " 'This Friday!!! Club Vault 3rd Floor EpiCentre http://t.co/7nU7pRxeul',\n",
       " \"'Cause you play me like a symphony play me till your fingers bleed. I'm your greatest masterpiece. You ruin me??\",\n",
       " \"babe I'm gonna ruin you if you let me stay\",\n",
       " \"@smoak_queen 'I'm going to be in so much trouble.'\",\n",
       " '@VileLunar I trickshot with a regular controller fucking infinite fading is so harm &gt;:(',\n",
       " 'awwww Baby Walter #rewatchingthepilot #TeamScorpion #Cyclone',\n",
       " '.@APHL responds: FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps http://t.co/cGdj3dRso9',\n",
       " 'Those that I have sworn to defend have proven themselves to be friends of the House Hailstorm.',\n",
       " '@LT3dave so many specs so much fan service so much lore destruction',\n",
       " 'USFS an acronym for United States Fire Service. http://t.co/8NAdrGr4xC',\n",
       " \"MY FAVS I'M SCREAMING SO FUCKING LOUD http://t.co/cP7c1cH0ZU\"]"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting 30 random from text column randomly\n",
    "random.sample(list((train_df.text)),k=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data incosistencies or redundant information found in the dataset are as follows\n",
    "\n",
    "* Upper case and lower case at unexpected location\n",
    "* Punctuations\n",
    "* Numbers in text \n",
    "* Use of cities, states and Country names. (Granularity problem)\n",
    "* Special characters such as \\x89ÛÒ and \\n\n",
    "* Hyperklinks\n",
    "* Tags in tweets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method below does the following to clean anomalies in 'location' column:\n",
    "\n",
    "* Changes all the text to lower case\n",
    "* Removes punctutations\n",
    "* Removes texts with numbers\n",
    "* Removes cities names if country/state names are mentioned. (High level granularity is maintained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to chaange text to lower case and remove punctionation\n",
    "def cleaning_location(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()    #lower case\n",
    "    text = text.split(',')[-1:][0].strip() # Removing city names when country/state name is present\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)  #removing punctuations\n",
    "    text = re.sub('\\w*\\d\\w*', '', text) #removing text with number\n",
    "\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Applying the method to location column\n",
    "train_df.location = train_df.location.apply(cleaning_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method below does the following to clean anomalies in 'keyword' column:\n",
    "\n",
    "* Changes all the text to lower case\n",
    "* Removes punctutations\n",
    "* replaces number with space (as %20 was found in middle of two words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_keyword(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()    ##lower case\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)  ##removing punctuations\n",
    "    text = re.sub('(\\d+)', ' ', text)   #replacing numbers with space\n",
    "    return text\n",
    "\n",
    "# Applying the method to keyword column\n",
    "train_df.keyword = train_df.keyword.apply(cleaning_keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method to clean anomalies in 'text' column does the following\n",
    "\n",
    "* Changes all the text to lower case\n",
    "* Removes words starting with @ to remove the tags and mentions example: @barackobama\n",
    "* Adds a column with hashtag values\n",
    "* Removes links\n",
    "* Removes punctuation\n",
    "* Removes words with numbers\n",
    "* Removes special characters examples: \\x89û,\\x89ûó etc \n",
    "* Removes '\\n' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Hasthags\"] = ''\n",
    "\n",
    "def retreive_hashtags(text):\n",
    "    hash_tag = ''\n",
    "    hash_tag = re.sub('#','',' '.join(re.findall('(#[A-Za-z]+[A-Za-z0-9-_]+)', text)))  #retreiving hastags\n",
    "    return hash_tag\n",
    "\n",
    "def cleaning_text(text):\n",
    "    \n",
    "    text = str(text)\n",
    "    text = text.lower()    ##lower case\n",
    "    \n",
    "    text = re.sub(r'@[A-Za-z]+[A-Za-z0-9-_]+', '',text) #removing any word starting with @   \\w\n",
    "    text = re.sub(r'https|www|http\\S+', '', text)  #removing any word starting with http\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)  ##removing punctuations\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)  #removing words with numbers\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text) # removing special characters\n",
    "    text.replace(\"\\n\",\"\")\n",
    "    return text\n",
    "\n",
    "train_df.Hasthags= train_df.text.apply(retreive_hashtags)\n",
    "\n",
    "# Applying the method to the text column in the dataframe\n",
    "train_df.text= train_df.text.apply(cleaning_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>Hasthags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>people receive wildfires evacuation orders in...</td>\n",
       "      <td>1</td>\n",
       "      <td>wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "      <td>Alaska wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7608</td>\n",
       "      <td>10869</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7609</td>\n",
       "      <td>10870</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>the out of control wild fires in california ...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7610</td>\n",
       "      <td>10871</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>s of volcano hawaii</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7611</td>\n",
       "      <td>10872</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>police investigating after an ebike collided w...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7612</td>\n",
       "      <td>10873</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>the latest more homes razed by northern califo...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     nan      nan   \n",
       "1         4     nan      nan   \n",
       "2         5     nan      nan   \n",
       "3         6     nan      nan   \n",
       "4         7     nan      nan   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     nan      nan   \n",
       "7609  10870     nan      nan   \n",
       "7610  10871     nan      nan   \n",
       "7611  10872     nan      nan   \n",
       "7612  10873     nan      nan   \n",
       "\n",
       "                                                   text  target  \\\n",
       "0     our deeds are the reason of this earthquake ma...       1   \n",
       "1                 forest fire near la ronge sask canada       1   \n",
       "2     all residents asked to shelter in place are be...       1   \n",
       "3      people receive wildfires evacuation orders in...       1   \n",
       "4     just got sent this photo from ruby alaska as s...       1   \n",
       "...                                                 ...     ...   \n",
       "7608  two giant cranes holding a bridge collapse int...       1   \n",
       "7609    the out of control wild fires in california ...       1   \n",
       "7610                               s of volcano hawaii        1   \n",
       "7611  police investigating after an ebike collided w...       1   \n",
       "7612  the latest more homes razed by northern califo...       1   \n",
       "\n",
       "              Hasthags  \n",
       "0           earthquake  \n",
       "1                       \n",
       "2                       \n",
       "3            wildfires  \n",
       "4     Alaska wildfires  \n",
       "...                ...  \n",
       "7608                    \n",
       "7609                    \n",
       "7610                    \n",
       "7611                    \n",
       "7612                    \n",
       "\n",
       "[7613 rows x 6 columns]"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A glimpse of cleaned data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       our deeds are the reason of this earthquake ma...\n",
       "1                   forest fire near la ronge sask canada\n",
       "2       all residents asked to shelter in place are be...\n",
       "3        people receive wildfires evacuation orders in...\n",
       "4       just got sent this photo from ruby alaska as s...\n",
       "                              ...                        \n",
       "7608    two giant cranes holding a bridge collapse int...\n",
       "7609      the out of control wild fires in california ...\n",
       "7610                                 s of volcano hawaii \n",
       "7611    police investigating after an ebike collided w...\n",
       "7612    the latest more homes razed by northern califo...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['our',\n",
       " 'deeds',\n",
       " 'are',\n",
       " 'the',\n",
       " 'reason',\n",
       " 'of',\n",
       " 'this',\n",
       " 'earthquake',\n",
       " 'may',\n",
       " 'allah',\n",
       " 'forgive',\n",
       " 'us',\n",
       " 'all']"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(train_df.text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shashanksharma/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
