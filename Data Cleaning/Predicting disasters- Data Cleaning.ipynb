{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re           # regular expression \n",
    "import string       # String Handling\n",
    "import random       #For selecting random rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the training data into a dataframe using pandas and viewing the top 20 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "#train_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 20 rows in 'Keyword' and 'Location' column are NaNs. Now Checking if there are nulls in other columns of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      "id          7613 non-null int64\n",
      "keyword     7552 non-null object\n",
      "location    5080 non-null object\n",
      "text        7613 non-null object\n",
      "target      7613 non-null int64\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking number of unique values in 'keywords' and 'location'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.keyword.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3342"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.location.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A glimpse at 50 rows from the 'locations' column selected randomly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This Is Paradise. Relax. ',\n",
       " 'Nairobi, Kenya',\n",
       " 'back in japan ??????????',\n",
       " '956',\n",
       " 'Fairfax, VA',\n",
       " 'Winnipeg, Manitoba',\n",
       " 'Somewhere in the Canada',\n",
       " 'Lyallpur, Pakistan',\n",
       " 'Suburban Detroit, Michigan',\n",
       " 'United States',\n",
       " 'Oregon, USA',\n",
       " 'Watch Those Videos -',\n",
       " 'Loughborough, England',\n",
       " 'ayr',\n",
       " 'Nashua NH',\n",
       " 'i got 1/13 menpa replies, omg',\n",
       " 'Ontario, Canada',\n",
       " '60th St (SS)',\n",
       " 'Daruka (near Tamworth) NSW',\n",
       " 'South, USA',\n",
       " \"Dil's Campsite\",\n",
       " 'Brazil ',\n",
       " 'Los Angeles, CA',\n",
       " 'International ',\n",
       " 'nap central',\n",
       " 'Denver, Colorado',\n",
       " '??????????????',\n",
       " 'Reston, VA, USA',\n",
       " 'Global-NoLocation',\n",
       " 'The Circle of Life',\n",
       " 'PSN: Pipbois ',\n",
       " 'Proudly Canadian!',\n",
       " 'El Paso, TX',\n",
       " 'Flipadelphia',\n",
       " '?????? ??? ?????? ????????',\n",
       " 'California, USA',\n",
       " '302???? 815',\n",
       " 'Crayford, London',\n",
       " 'Pacific Northwest',\n",
       " '9/1/13',\n",
       " 'Aztec NM',\n",
       " 'm3, k, a, d',\n",
       " 'Roanoke VA',\n",
       " 'shoujo hell ',\n",
       " 'South West, England',\n",
       " 'Davis, California',\n",
       " 'To The Right of You!',\n",
       " '11th dimension, los angeles',\n",
       " 'Harlingen, TX',\n",
       " 'buffalo / madrid / granada']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(list((train_df.location.unique())),k=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nan', 'ablaze', 'accident', 'aftershock', 'airplane accident',\n",
       "       'ambulance', 'annihilated', 'annihilation', 'apocalypse',\n",
       "       'armageddon', 'army', 'arson', 'arsonist', 'attack', 'attacked',\n",
       "       'avalanche', 'battle', 'bioterror', 'bioterrorism', 'blaze',\n",
       "       'blazing', 'bleeding', 'blew up', 'blight', 'blizzard', 'blood',\n",
       "       'bloody', 'blown up', 'body bag', 'body bagging'], dtype=object)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.keyword.unique()[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data incosistencies found in the Location and Keyword column are as follows\n",
    "\n",
    "* Upper case and lower case\n",
    "* Punctuations\n",
    "* Numbers in text \n",
    "* Use of cities, states and Country names.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method to clean anomalies in 'location' column does the following\n",
    "\n",
    "* Change all the text to lower case\n",
    "* Removes punctutations\n",
    "* removes texts with numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to chaange text to lower case and remove punctionation\n",
    "def cleaning_location(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()    ##lower case\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)  ##removing punctuations\n",
    "    text = re.sub('\\w*\\d\\w*', '', text) ##removing text with number\n",
    "    return text\n",
    "\n",
    "# Applying the method to location column\n",
    "train_df.location = train_df.location.apply(cleaning_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method to clean anomalies in 'keyword' column does the following\n",
    "\n",
    "* Change all the text to lower case\n",
    "* Removes punctutations\n",
    "* replaces number with space ( as %20 was found in middle of two words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_keyword(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()    ##lower case\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)  ##removing punctuations\n",
    "    text = re.sub('(\\d+)', ' ', text)   #replacing numbers with space\n",
    "    return text\n",
    "\n",
    "# Applying the method to keyword column\n",
    "train_df.keyword = train_df.keyword.apply(cleaning_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['american weapons and support are fueling a bloody air war in yemen ',\n",
       " ' strange loud impact bang noises under train to epsom about to arrive wimbledon',\n",
       " ' thank you i survived ',\n",
       " 'video were picking up bodies from water rescuers are searching for hundreds of migrants in the mediterran ',\n",
       " '  well i think that sounds like a fine plan where little derailment is possible so i applaud you ',\n",
       " 'people who try to jwalk while an ambulance is passing i hate you',\n",
       " 'check these out     nsfw',\n",
       " 'more homes razed by northern calif wildfire  sandiego ',\n",
       " ' when u do a fatality and like the corpse is still jittering',\n",
       " 'the latest more homes razed by northerncalifornia wildfire  zippednews ',\n",
       " 'ahmazing story of the power animal rescuers have a starving homeless dog with no future was rescued by a person ',\n",
       " ' i hope that mountain dew erodes your throat and floods your lungs leaving you to drown to death',\n",
       " '  do anything to fix that of the few people he had every trusted in his life charles was one of the casualties',\n",
       " 'truck crash on  at  in lebanon is a fatality very sad expect long delays through the morning',\n",
       " 'more natural disaster research urgent  via jakartapost',\n",
       " ' us military and nato are fighting talibans too',\n",
       " 'suspect in latest theater attack had psychological issues ',\n",
       " 'shirley caesar  windstorm  nowplaying listenlive',\n",
       " 'volleyball attack ii volleyball training machine  sets simulation   ',\n",
       " 'we just happened to get on the same road right behind the buses im dead serious',\n",
       " 'finna storm fuck my back boutta start hurting like a mf ',\n",
       " 'philippines must protect internally displaced persons warns un expert ',\n",
       " 'windstorm board oks rate hike before change  politics txlege twia',\n",
       " ' watching news of wild fires and hope all is ok',\n",
       " 'screams in  different languages',\n",
       " 'they evacuated the mall again ',\n",
       " 'smoke detectors not required in all buildings an office building on shevlinhixon drive was on fire there we ',\n",
       " ' are you okay i electrocute you too badly right',\n",
       " ' hell is just a fraction of his belief of total annihilation destruction of usa  ',\n",
       " 'fire truck and ambulance in  phase  hope everyones okay prayforsaipan']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting 30 random from text column randomly\n",
    "random.sample(list((train_df.text)),k=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method to clean anomalies in 'text' column does the following\n",
    "\n",
    "* Change all the text to lower case\n",
    "* Removes words starting with @ to remove the tags and mentions example: @barackobama\n",
    "* Removes links\n",
    "* Removes punctuation\n",
    "* Removes words with numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()    ##lower case\n",
    "    text = re.sub(r'@\\w+', '',text) ##removing any word starting with @\n",
    "    text = re.sub(r'http\\S+', '', text)  ##removing any word starting with http\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)  ##removing punctuations\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)  #removes words with numbers\n",
    "    return text \n",
    "\n",
    "# Applying the method to the text column in the dataframe\n",
    "train_df.text = train_df.text.apply(cleaning_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' whao  nigerian refugees repatriated from cameroon ',\n",
       " ' wk of rainier diet and my street seward park ave is inundated w bypass traffic so  whats your plan ',\n",
       " 'and even if the stars and moon collide \\x89ûó oh oh i never want you back to my life you can take your words and all ',\n",
       " 'hollywood movie about trapped miners released in chile ',\n",
       " ' your tweet was quoted by   ',\n",
       " 'i did another one i did another one you still aint done shit about the other one nigga body bagging meek',\n",
       " ' \\n\\npakistan says army helicopter has crashed in countrys restive northwest   fox news',\n",
       " '  pandemonium in aba as woman delivers baby without face  ',\n",
       " 'latestnews police officer wounded suspect dead after exchanging shots richmond va ap \\x89ûó a richmond pol ',\n",
       " 'brooke just face timed me at the concert and just screamed for  minutes straight',\n",
       " 'lets fraction the vital need for our fatalities  how would you break it down in education econom ',\n",
       " 'lets not forget our wounded female veterans ',\n",
       " 'have you read this awesome book yet  the two trillion dollar meltdown  ',\n",
       " 'usgs eq m    ssw of anza california       earthquake',\n",
       " ' exactly thats why the lesnarcena match from summerslam last year was so great because brock annihilated a guy whos',\n",
       " 'summer is lovely',\n",
       " 'why are you engulfed by low selfimage take the quiz  ',\n",
       " 'national briefing  west california spring oil spill estimate grows documents released on wednesday disclos ',\n",
       " '   please blizzard we love you',\n",
       " 'quirk injury laws news is out  stories via ',\n",
       " 'orchid  sign of the witch ',\n",
       " 'the man who can drive himself further once the effort gets painful is the man who will win \\nroger bannister',\n",
       " 'i eat because it makes my mouth explode with joy and my soul rise upwards   ',\n",
       " '  south gate police officers and  huntington park officers arrested after child abuse investigation at boot camp',\n",
       " 'the  fatburning routine that\\x89ûªs also really fun  fat weightless  fatburning burnfat skinny workout',\n",
       " 'fair enough we have two of the best attacking wingers in the prem in hazard and willian who will basically start every game ',\n",
       " 'ignition knock detonation sensor connectorconnecto dorman   ',\n",
       " 'join the providence health amp services team see our latest nursing job opening here  torrance ca hiring',\n",
       " 'shipping logistics enca  fatalities as migrant boat capsizes in med with hundreds onboard \\x89û  capsized as i  ',\n",
       " ' ahh youre bomb baby ']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(list((train_df.text)),k=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
